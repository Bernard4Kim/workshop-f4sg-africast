---
title: "Lab exercise: day 4"
editor: visual
---

# Learn

# Apply

## Specify and traing ETS models

We now want to apply the Exponential Smoothing family of models to forecast dose administrated.

:::{.callout-tip}
Remember the following from ETS  (E: Error, T:Trend, S: Seasonality) function:

    - N: None (No trend, no seasonality) 
    - A: additive 
    - Ad: additive damped 
    - M: multiplicative
:::

Complete the R code to train exponential smoothing models on the `vaccine_administrated_tsb`:

```{r}
fit_ets <- vaccine_administrated_tsb |>
  model(
    --- = ---(---)
  )
```

:::{.callout-caution}
If you don't provide terms inside ETS(), then it is an automatic ETS! It will examine different models and return the one with lowest AICc.
:::

## Observe model table and extract model's output

let's now observe the model table `fit_ets`. 
:::{.callout-note}
### Question
What type of data structure is `fit_ets`? How many rows and columns are present, and what do they represent?
:::

Complete the below R codes and run to understand model's outputs:

Use `report()`:

```{r}
fit_ets |> ---()
```

:::{.callout-caution}
## Question
Which model is returned, what are its components and parameter values?
:::

Use `tidy()`:

```{r}
fit_ets |> ---()
```

Use `glance()`:

```{r}
fit_ets |> ---()
```

You can also observe the values corresponding to level, trend, seasonal components in ETS framework. Each column corresponds to one components.

Complete the R code and run to observe the selected model components:

```{r}
fit_ets |> ---()
```

:::{.callout-caution}
## Question
Could you describe what each row and column represent?
:::

## Generate forecasts using ETS

Now, we can forecast with the trained ETS model. Complete and run the following code to produce forecasts:

```{r}
forecast_ets <- fit_ets |>
  ---(h = ---) 
forecast_ets
```

:::{.callout-note}
### Question
What type of data structure is it? What each row and column represent?
:::

## Visualise forecasts:

You can also visualize forecasts:

```{r}
forecast_ets |>
  autoplot(filter_index(---, "2020" ~ .), level = NULL)
```


## Detrmine model components and parameters manually

You can use the following specific functions: `error()`, `trend()`, `season()` to manually specify the type of pattern ("N", "A", "Ad", "M") and also their corresponding parameters, if you wish.


In the following R-chunk, you can change parameters and the type of pattern to see their impact on fitting and forecast

```{r alpha}
vaccine_ets <- vaccine_administrated_tsb |>
  model(
    `alpha = 0.05` = ETS(--- ~ error("A") + trend("A", alpha = .05) + season("N")),
    `alpha = 0.15` = ETS(--- ~ error("A") + trend("A", alpha = .15) + season("N")),
    `alpha = 0.5` = ETS(--- ~ error("A") + trend("A", alpha = .5) + season("N")),
    `alpha = 0.9` = ETS(--- ~ error("A") + trend("A", alpha = .9) + season("N"))
  )

vaccine_ets |> augment() |> filter_index("2020" ~ .) |> 
  ggplot(aes(x=month))+
  geom_line(aes(y=dose_adminstrated, colour= "Actual"))+
  geom_line(aes(y=.fitted, colour= factor(.model)))+
  ggthemes::scale_color_colorblind()+
  labs(colour ="")
```

## ARIMA

## Specify and train ARIMA model

If you want this function automatically determines the order of autoregressive and moving average orders and their parameters, then you don't need to provide arguments inside ARIMA(). The function will examine different models (combinations of p=0,1,2,.. and q =0,1,2,.., P=0,1,2,.. and Q =0,1,2,..) and return the one with lowest AICc.

```{r}
fit_arima <- vaccine_administrated_tsb |>
  model(
    --- = ---(---)
  )
```

:::{.callout-caution}
If we don't provide terms inside ARIMA(), then it is an automatic model! It will examine different models and return the one with lowest AICc.
:::

let's now observe the fitted model

```{r}
fit_arima |> 
  filter() |> 
  ---()
```

:::{.callout-note}
### Question
What type of data structure is it? What each row and column represent?
:::

## Extract model's output

use `report()`

```{r}
fit_arima |> 
  ---()
```


Use `tidy()`:

```{r}
fit_arima |> ---()
```

Use `glance()`:

```{r}
fit_arima |> ---()
```

## Generate forecasts using ARIMA

Now, we can forecast with the fitted ARIMA model:

```{r}
vaccine_fcst_arima <- --- |> ---(h = ---)  
```

## Visualize forecasts

you can visualize your forecast:

```{r}
vaccine_fcst_arima |> 
  autoplot(filter_index(---, "2020" ~ .))
```


## Determine model components manually

You can also specify the order of p,q,P,Q using specific function `pdq()` and `PDQ()`:

```{r}
fit_arima_manual <- --- |>
  model(
    automatic_arima = ---(---),
    arima1=---(--- ~ ---(1,1,1)+---(0,0,1)),
    arima2 = ---(--- ~ ---(3,1,0)+---(1,0,0))
  )
```


<!-- # If you want to know more -->

<!-- ## Stationary vs. non-stationairy time series -->

<!-- look at monthly data, do they look like stationary data (stationairy data is roughly a horizontal line)? We can start by looking at a time plot: -->

<!-- ```{r} -->
<!-- ambulance_demand_total |> autoplot() -->
<!-- ``` -->

<!-- Now, look at the autocorrelation plot: -->

<!-- ```{r} -->
<!-- ambulance_demand_total |> ACF(lag_max = 21) |> autoplot() -->
<!-- ``` -->

<!-- there are significant autocorrelation lags which decreases as lag increases. This indicate a non-statioaniry series. -->

<!-- You can also do a statistical test (KPSS) to see whether time series is stationary or not. we use the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test. In this test, the null hypothesis is that the data are stationary, and we look for evidence that the null hypothesis is false. Consequently, small p-values (e.g., less than 0.05) suggest that time series is non-stationairy and differencing is required to make it stationairy. The test can be computed using the unitroot_kpss() function. -->

<!-- To conduct the test we use `features()` function: -->

<!-- ```{r test} -->
<!-- ambulance_demand_total |> features(demand,unitroot_kpss) -->
<!-- ``` -->

<!-- Does it tell if data is non-stationary? -->

<!-- You can use the same function but instead of `unitroot_kpss` , you can use `unitroot_ndiffs`. This will tell you how many differencing you need to make the time series stationairy: -->

<!-- ```{r ndiff} -->
<!-- ambulance_demand_total |> features(demand,unitroot_ndiffs) -->
<!-- ``` -->

<!-- This will determine the value of `d=` in ARIMA(p,d,q). -->

<!-- ```{r nsdiff} -->
<!-- ambulance_demand_total |> features(demand,unitroot_ndiffs) -->
<!-- ``` -->

<!-- If seasonality is present , you need seasonal differencing to make series stationary. this will tell us what would be the vale of D in ARIMA (p,d,q) (P,D,Q) -->

<!-- ## Determining values of p,q , P,Q -->

<!-- ```{r determine-order} -->
<!-- ambulance_demand_total |> ACF(demand, lag_max = 21) |> autoplot()# what does the ACF tell us?  -->
<!-- ambulance_demand_total |> PACF(demand) |> autoplot()# what is PACF? -->
<!-- ``` -->

<!-- Using ACF and PACF help us to determine the order of p, q. look at the properties of MA(q) and AR(p) in slides to ssee how ACF and PACF can be used to determine p,q,P,Q -->

<!-- ## Using simulation to understand ARMA process -->

<!-- You can simulate different ARMA processes and their parameters, this might be helpful in understanding how ARMA works. Let's start with AR(1): -->

<!-- This is the simulation for AR(1) with Phi= 0.9 -->

<!-- ```{r ar1} -->
<!-- set.seed(1) -->
<!-- ar1 <- arima.sim(list(order=c(1,0,0),ar=0.9),n=1000) -->
<!-- ar1_tsb <- tibble(day=seq(1,length(ar1),1), ar=ar1) |> as_tsibble(index = day) -->
<!-- ar1_tsb |> autoplot() -->
<!-- ar1_tsb |> ACF |>  autoplot() -->
<!-- ar1_tsb |> PACF |>  autoplot() -->
<!-- ``` -->

<!-- Now, simulate AR(2) with phi1 and phi2 -->

<!-- ```{r ar2} -->
<!-- set.seed(1) -->
<!-- ar2 <- arima.sim(list(order=c(2,0,0),ar=c(-0.2,0.35)),n=1000) -->
<!-- ar2_tsb <- tibble(day=seq(1,length(ar1),1), ar=ar2) |> as_tsibble(index = day) -->
<!-- ar2_tsb |> autoplot() -->
<!-- ar2_tsb |> ACF |>  autoplot() -->
<!-- ar2_tsb |> PACF |>  autoplot() -->
<!-- ``` -->

<!-- ### MA -->

<!-- ```{r ma1} -->
<!-- set.seed(1) -->
<!-- ma1 <- arima.sim(list(order=c(0,0,1),ma=0.7),n=10000) -->
<!-- ma1_tsb <- tibble(day=seq(1,length(ma1),1), ma=ma1) |> as_tsibble(index = day) -->
<!-- ma1_tsb |> autoplot() -->
<!-- ma1_tsb |> ACF |>  autoplot() -->
<!-- ma1_tsb |> PACF |>  autoplot() -->
<!-- ``` -->

<!-- ```{r ma2} -->
<!-- set.seed(1) -->
<!-- ma2 <- arima.sim(list(order=c(0,0,2),ma=c(0.3,0.5)),n=10000) -->
<!-- ma2_tsb <- tibble(day=seq(1,length(ma1),1), ma=ma1) |> as_tsibble(index = day) -->
<!-- ma2_tsb |> autoplot() -->
<!-- ma2_tsb |> ACF |>  autoplot() -->
<!-- ma2_tsb |> PACF |>  autoplot() -->
<!-- ``` -->

<!-- ### ARMA -->

<!-- ```{r arma} -->
<!-- set.seed(1) -->
<!-- phi <- 0.9 -->
<!-- theta <- 0.5 -->
<!-- my_model <- list(order=c(1,0,1),ar=phi,ma=theta) -->
<!-- arma11 <- arima.sim(my_model,n=10000) -->
<!-- arma11_tsb <- tibble(day=seq(1,length(arma11),1), arma=arma11) |> as_tsibble(index = day) -->
<!-- arma11_tsb |> autoplot() -->
<!-- arma11_tsb |> ACF |>  autoplot() -->
<!-- arma11_tsb |> PACF |>  autoplot() -->
<!-- ``` -->
