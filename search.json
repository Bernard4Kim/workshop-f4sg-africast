[
  {
    "objectID": "feedback.html#feedback",
    "href": "feedback.html#feedback",
    "title": "Tidy time series & forecasting in R",
    "section": "Feedback",
    "text": "Feedback"
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "Tidy time series & forecasting in R",
    "section": "Course Overview",
    "text": "Course Overview\nForecasting is a valuable tool that allows organizations to make informed decisions about the future. Time series forecasting, in particular, uses historical data to predict future trends over time. This technique has extensive applications across a wide range of fields, including finance and economics, health and humanitarian operations, supply chain management, and more. By analyzing trends and patterns in data, time series forecasting can help decision-makers identify potential challenges and opportunities, and plan accordingly.\nIt is important for researchers in Low- and Middle-Income Countries (LMICs) to develop technical skill in data analysis and forecasting techniques, which are essential for accurate and reliable forecasting. By having these skills, researchers can analyze data, identify trends and patterns, and develop robust forecasting models to make informed decisions that can improve resource allocation and planning in LMICs. Additionally, researchers can collaborate with policy makers and stakeholders to ensure that the forecast results are integrated into decision-making processes, leading to more efficient and effective resource management strategies.\nThis workshop is part of the Forecasting for Social Good (F4SG) initiative, and will run online from the 23rd-27th October 2023."
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Tidy time series & forecasting in R",
    "section": "Learning objectives",
    "text": "Learning objectives\nDuring the training, participants will gain knowledge and skills in:\n\nPreparing time series data for analysis and exploration.\nExtracting and computing useful features from time series data and effectively visualizing it.\nIdentifying appropriate forecasting algorithms for time series and selecting the best approach for the data at hand."
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "Tidy time series & forecasting in R",
    "section": "Instructor",
    "text": "Instructor\n Mitchell O’Hara-Wild (he/him) is a PhD student at Monash University, creating new techniques and tools for forecasting large collections of time series with Rob Hyndman and George Athanasopoulos. He is the lead developer of the tidy time-series forecasting tools fable and feasts, and has co-developed the widely used forecast package since 2015. Mitchell also operates a data consultancy, and has worked on many forecasting projects that have supported decision making and planning for businesses and governments. He is an award-winning educator, and has taught applied forecasting at Monash University and various forecasting workshops around the world."
  },
  {
    "objectID": "index.html#instructor-1",
    "href": "index.html#instructor-1",
    "title": "Tidy time series & forecasting in R",
    "section": "Instructor",
    "text": "Instructor\n\nTBC"
  },
  {
    "objectID": "index.html#required-equipment",
    "href": "index.html#required-equipment",
    "title": "Tidy time series & forecasting in R",
    "section": "Required equipment",
    "text": "Required equipment\nPlease have your own laptop capable of running R."
  },
  {
    "objectID": "index.html#required-software",
    "href": "index.html#required-software",
    "title": "Tidy time series & forecasting in R",
    "section": "Required software",
    "text": "Required software\nTo be able to complete the exercises of this workshop, please install a suitable IDE (such as RStudio), a recent version of R (4.1+) and the following packages.\n\nTime series packages and extensions\n\nfpp3, sugrrants\n\ntidyverse packages and friends\n\ntidyverse, fpp3\n\n\nThe following code will install the main packages needed for the workshop.\ninstall.packages(c(\"tidyverse\",\"fpp3\", \"GGally\", \"sugrrants\"))\nPlease have the required software installed and pre-work completed before attending the workshop."
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "This work is licensed under a Creative Commons Attribution 4.0 International License."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Time\n\n\nSession\n\n\n\n\n\n\n08:00-09:30\n\n\nBasics of time series and data structures\n\n\n\n\n09:45-11:15\n\n\nTime series patterns and basic graphics\n\n\n\n\n16:30-18:00\n\n\nExercises\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "schedule.html#day-2",
    "href": "schedule.html#day-2",
    "title": "Schedule",
    "section": "Day 2",
    "text": "Day 2\n\n\n\n\n\n\nTime\n\n\nSession\n\n\n\n\n\n\n08:00-09:30\n\n\nTransforming / adjusting time series\n\n\n\n\n09:45-11:15\n\n\nComputing and visualizing features\n\n\n\n\n16:30-18:00\n\n\nExercises\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "schedule.html#day-3",
    "href": "schedule.html#day-3",
    "title": "Schedule",
    "section": "Day 3",
    "text": "Day 3\n\n\n\n\n\n\nTime\n\n\nSession\n\n\n\n\n\n\n08:00-09:30\n\n\nBasic modeling / forecasting\n\n\n\n\n09:45-11:15\n\n\nForecasting with regression, how to represent temporal structure with regressors\n\n\n\n\n16:30-18:00\n\n\nExercises\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "schedule.html#day-4",
    "href": "schedule.html#day-4",
    "title": "Schedule",
    "section": "Day 4",
    "text": "Day 4\n\n\n\n\n\n\nTime\n\n\nSession\n\n\n\n\n\n\n08:00-09:30\n\n\nARIMA\n\n\n\n\n09:45-11:15\n\n\nETS\n\n\n\n\n16:30-18:00\n\n\nExercises\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "schedule.html#day-5",
    "href": "schedule.html#day-5",
    "title": "Schedule",
    "section": "Day 5",
    "text": "Day 5\n\n\n\n\n\n\nTime\n\n\nSession\n\n\n\n\n\n\n08:00-09:30\n\n\nBasic training and test accuracy\n\n\n\n\n09:45-11:15\n\n\nResidual diagnostics and cross validation\n\n\n\n\n16:30-18:00\n\n\nExercises\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "sessions/break.html",
    "href": "sessions/break.html",
    "title": "Coffee Break",
    "section": "",
    "text": "Time for a coffee break!\nFeel free to ask me some questions, or simply enjoy the break."
  },
  {
    "objectID": "sessions/day1/exercises.html",
    "href": "sessions/day1/exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "We’ve prepared an exercises project with some starter code for each of the sessions. You can download and open this project using:\n\nusethis::use_course(\"https://workshop.mitchelloharawild.com/f4sg-africa/exercises.zip\")"
  },
  {
    "objectID": "sessions/day1/exercises.html#creating-a-time-series-tibble-a-tsibble",
    "href": "sessions/day1/exercises.html#creating-a-time-series-tibble-a-tsibble",
    "title": "Exercises",
    "section": "Creating a time series tibble (a tsibble!)",
    "text": "Creating a time series tibble (a tsibble!)\nA tsibble is a rectangular data frame that contains:\n\na time column: the index\nidentifying column(s): the key variables\nvalues (the measured variables)\n\nYou usually create a tsibble by converting an existing dataset (read from a file) with as_tsibble(). For example, let’s look at the production of rice in Guinea.\n\n# Read in the dataset using readr\nlibrary(readr)\nguinea_rice <- read_csv(\"data/guinea_rice.csv\")\n\n# Convert the dataset to a tsibble\n# Here the index variable is 'Year', and there are no key variables.\n# The 'Production' variable is what we're interested in forecasting (the measured variable).\nlibrary(tsibble)\nguinea_rice <- as_tsibble(guinea_rice, index = Year)\n\nA tsibble enables time-aware data manipulation, which makes it easy to work with time series. It also has extra checks to prevent common errors, while these can be frustrating at first they are important in correctly analysing your data.\nThere are two common mistakes when creating a tsibble, which we’ll see in the next example of Australian accommodation.\n\n# Read in the dataset using readr\naus_accommodation <- read_csv(\"data/aus_accommodation.csv\")\n\n# Try to convert the dataset to a tsibble\naus_accommodation <- as_tsibble(aus_accommodation, index = Date)\n\nError in `validate_tsibble()`:\n! A valid tsibble must have distinct rows identified by key and index.\nℹ Please use `duplicates()` to check the duplicated rows.\n\n\n\n\n\n\n\n\nThat didn’t work…\n\n\n\nReading the error says we have ‘duplicated rows’. What this means is that we have two or more rows in the dataset for the same point in time. In time series it isn’t possible to get two different values at the same time, but it is possible to measure several different things at the same time.\n\n\nWhen you get this error, consider if any of the dataset’s variables can identify individual series.\n\n\n\n\n\n\nTip\n\n\n\nThe identifying key variables of a time series are usually character variables, and the measured variables are almost always numeric.\n\n\n\naus_accommodation\n\n# A tibble: 592 × 5\n   Date       State                        Takings Occupancy   CPI\n   <date>     <chr>                          <dbl>     <dbl> <dbl>\n 1 1998-01-01 Australian Capital Territory    24.3      65    67  \n 2 1998-04-01 Australian Capital Territory    22.3      59    67.4\n 3 1998-07-01 Australian Capital Territory    22.5      58    67.5\n 4 1998-10-01 Australian Capital Territory    24.4      59    67.8\n 5 1999-01-01 Australian Capital Territory    23.7      58    67.8\n 6 1999-04-01 Australian Capital Territory    25.4      61    68.1\n 7 1999-07-01 Australian Capital Territory    28.2      66    68.7\n 8 1999-10-01 Australian Capital Territory    25.8      60    69.1\n 9 2000-01-01 Australian Capital Territory    27.3      60.9  69.7\n10 2000-04-01 Australian Capital Territory    30.1      64.7  70.2\n# ℹ 582 more rows\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWhich of these variable(s) identifies each time series?\n\n\nIn this dataset we have accommodation data from all 8 states in Australia, and so we need to specify State as a key variable when creating our tsibble.\n\n# Try to convert the dataset to a tsibble\naus_accommodation <- as_tsibble(aus_accommodation, index = Date, key = State)\naus_accommodation\n\n# A tsibble: 592 x 5 [1D]\n# Key:       State [8]\n   Date       State                        Takings Occupancy   CPI\n   <date>     <chr>                          <dbl>     <dbl> <dbl>\n 1 1998-01-01 Australian Capital Territory    24.3      65    67  \n 2 1998-04-01 Australian Capital Territory    22.3      59    67.4\n 3 1998-07-01 Australian Capital Territory    22.5      58    67.5\n 4 1998-10-01 Australian Capital Territory    24.4      59    67.8\n 5 1999-01-01 Australian Capital Territory    23.7      58    67.8\n 6 1999-04-01 Australian Capital Territory    25.4      61    68.1\n 7 1999-07-01 Australian Capital Territory    28.2      66    68.7\n 8 1999-10-01 Australian Capital Territory    25.8      60    69.1\n 9 2000-01-01 Australian Capital Territory    27.3      60.9  69.7\n10 2000-04-01 Australian Capital Territory    30.1      64.7  70.2\n# ℹ 582 more rows\n\n\nHurray, we have a tsibble! 🎉\n\n\n\n\n\n\nHowever there’s still one thing that isn’t right…\n\n\n\nIn the first row of the output we see [1D] - this means that the frequency of the data is daily.\n\n\nLooking at the index column (Date), we can see that each point in time is three months apart - or quarterly. This is another common mistake when working with time series, you need to set the appropriate temporal granularity.\n\n\n\n\n\n\nWhat is temporal granularity?\n\n\n\nTemporal granularity is the resolution in time. The time variable needs to match this resolution.\nIn this example, a date was used to represent quarters, but instead we must use yearquarter() to match the temporal granularity.\nHere’s a helpful list of common granularities:\n\nas.integer(): annual data (as above)\nyearquarter(): Quarterly data (shown here)\nyearmonth(): Monthly data\nyearweek(): Weekly data\nas.Date(): Daily data\nas.POSIXct(): Sub-daily data\n\n\n\nTo use the appropriate temporal granularity, we first must change our Date column before creating the tsibble.\n\n# Convert the `Date` column to quarterly with dplyr\nlibrary(dplyr)\naus_accommodation <- aus_accommodation |> \n  mutate(Date = yearquarter(Date)) |> \n  as_tsibble(index = Date, key = State)\naus_accommodation\n\n# A tsibble: 592 x 5 [1Q]\n# Key:       State [8]\n      Date State                        Takings Occupancy   CPI\n     <qtr> <chr>                          <dbl>     <dbl> <dbl>\n 1 1998 Q1 Australian Capital Territory    24.3      65    67  \n 2 1998 Q2 Australian Capital Territory    22.3      59    67.4\n 3 1998 Q3 Australian Capital Territory    22.5      58    67.5\n 4 1998 Q4 Australian Capital Territory    24.4      59    67.8\n 5 1999 Q1 Australian Capital Territory    23.7      58    67.8\n 6 1999 Q2 Australian Capital Territory    25.4      61    68.1\n 7 1999 Q3 Australian Capital Territory    28.2      66    68.7\n 8 1999 Q4 Australian Capital Territory    25.8      60    69.1\n 9 2000 Q1 Australian Capital Territory    27.3      60.9  69.7\n10 2000 Q2 Australian Capital Territory    30.1      64.7  70.2\n# ℹ 582 more rows\n\n\nNow we have a tsibble that’s ready to use! In the first row of the output you should now see [1Q] indicating that the data is quarterly. You can also see the second row shows us our key variable, State. Next to this is [8], which tells us that this dataset contains 8 time series (one for each of Australia’s states).\n\n\n\n\n\n\nPipes\n\n\n\nWhen chaining together multiple functions, it’s helpful to use the pipe operator (|>).\nThe pipe allows you to read the functions in the order that they are used - much like a sentence!\nMore information is here: https://r4ds.hadley.nz/workflow-style.html#sec-pipes\n\n\nThat’s all you need to know about creating a tidy time series tsibble 🌈.\n\n\n\n\n\n\nYour turn!\n\n\n\nCreate a tsibble for the number of tourists visiting Australia contained in data/tourism.csv.\nSome starter code has been provided for you in the day 1 exercises.\nHint: this dataset contains multiple key variables that need to be used together. You can specify multiple keys with as_tsibble(key = c(a, b, c))."
  },
  {
    "objectID": "sessions/day1/exercises.html#manipulating-time-series",
    "href": "sessions/day1/exercises.html#manipulating-time-series",
    "title": "Exercises",
    "section": "Manipulating time series",
    "text": "Manipulating time series\nOften you want to work with specific series, or perhaps the sum up the values across multiple series. We can use the same dplyr functions that are used in data analysis to explore our time series. Let’s focus on a single state from the Australian accommodation example - here we use filter() to keep only the Queensland data.\n\naus_accommodation |> \n  filter(State == \"Queensland\")\n\n# A tsibble: 74 x 5 [1Q]\n# Key:       State [1]\n      Date State      Takings Occupancy   CPI\n     <qtr> <chr>        <dbl>     <dbl> <dbl>\n 1 1998 Q1 Queensland    230.      54    67  \n 2 1998 Q2 Queensland    219.      54    67.4\n 3 1998 Q3 Queensland    268.      64    67.5\n 4 1998 Q4 Queensland    279.      61    67.8\n 5 1999 Q1 Queensland    241.      55    67.8\n 6 1999 Q2 Queensland    235.      56    68.1\n 7 1999 Q3 Queensland    286.      65    68.7\n 8 1999 Q4 Queensland    288.      61    69.1\n 9 2000 Q1 Queensland    253.      54.7  69.7\n10 2000 Q2 Queensland    253.      56.5  70.2\n# ℹ 64 more rows\n\n\nMaybe we wanted to focus on the more recent data, only keeping observations after 2010. Note that multiple conditions (both time and place) can be included inside a single filter() function.\n\naus_accommodation |> \n  filter(State == \"Queensland\", Date >= yearquarter(\"2010 Q1\"))\n\n# A tsibble: 26 x 5 [1Q]\n# Key:       State [1]\n      Date State      Takings Occupancy   CPI\n     <qtr> <chr>        <dbl>     <dbl> <dbl>\n 1 2010 Q1 Queensland    464.      57.4  95.2\n 2 2010 Q2 Queensland    461.      58.5  95.8\n 3 2010 Q3 Queensland    573.      68.9  96.5\n 4 2010 Q4 Queensland    562.      64.8  96.9\n 5 2011 Q1 Queensland    471.      58.1  98.3\n 6 2011 Q2 Queensland    489.      61    99.2\n 7 2011 Q3 Queensland    592.      70.5  99.8\n 8 2011 Q4 Queensland    587.      66.9  99.8\n 9 2012 Q1 Queensland    530.      62.3  99.9\n10 2012 Q2 Queensland    519.      62.6 100. \n# ℹ 16 more rows\n\n\nLet’s try seeing the total accommodation Takings and Occupancy for all of Australia. For this, we can use the summarise() function to summarise information across multiple rows.\n\naus_accommodation |> \n  summarise(Takings = sum(Takings), Occupancy = sum(Occupancy))\n\n# A tsibble: 74 x 3 [1Q]\n      Date Takings Occupancy\n     <qtr>   <dbl>     <dbl>\n 1 1998 Q1    949.      469 \n 2 1998 Q2    875.      431 \n 3 1998 Q3    981.      458 \n 4 1998 Q4   1036.      468 \n 5 1999 Q1    997.      460 \n 6 1999 Q2    940.      447 \n 7 1999 Q3   1062.      481 \n 8 1999 Q4   1105.      474 \n 9 2000 Q1   1088.      465.\n10 2000 Q2   1039.      460.\n# ℹ 64 more rows\n\n\n\n\n\n\n\n\nThe index and summarise()\n\n\n\nWe still have our Date variable as it is automatically grouped when working with tsibble.\n\n\nWhat about calculating the annual takings, not quarterly? For this we use a special grouping function called index_by().\n\nlibrary(lubridate)\naus_accommodation |> \n  index_by(Year = year(Date)) |> \n  summarise(Takings = sum(Takings), Occupancy = sum(Occupancy))\n\n# A tsibble: 19 x 3 [1Y]\n    Year Takings Occupancy\n   <dbl>   <dbl>     <dbl>\n 1  1998   3841.     1826 \n 2  1999   4104.     1862 \n 3  2000   4725.     1834.\n 4  2001   4766.     1819.\n 5  2002   4865.     1848 \n 6  2003   5277.     1887.\n 7  2004   5675.     1950.\n 8  2005   6189.     1996.\n 9  2006   6783.     2054.\n10  2007   7443.     2107.\n11  2008   7897.     2074.\n12  2009   7629.     2024.\n13  2010   8088.     2081 \n14  2011   8534.     2089.\n15  2012   8965.     2088 \n16  2013   8992.     2048.\n17  2014   9477.     2031.\n18  2015  10242.     2069.\n19  2016   5080.     1034.\n\n\n\n\n\n\n\n\nYour turn!\n\n\n\nUsing the tourism dataset, create an annual time series of the Purpose of travel for visitors to Australia (summing over State and Region)\nSome starter code has been provided for you in the day 1 exercises.\nHint: think about which key variables should be kept with group_by(), and how the index should be changed using index_by() then summarise().\n\n\nWhat if we didn’t want a time series at all? To calculate the total takings over all of time, we convert back to an ordinary data frame with as_tibble() and then summarise().\n\nlibrary(lubridate)\naus_accommodation |> \n  as_tibble() |> \n  summarise(Takings = sum(Takings), Occupancy = sum(Occupancy))\n\n# A tibble: 1 × 2\n  Takings Occupancy\n    <dbl>     <dbl>\n1 128571.    36720.\n\n\nWhich state has had the most accommodation takings in 2010? Let’s calculate total takings by state for 2010, and sort them with arrange().\n\naus_accommodation |> \n  filter(year(Date) == 2010) |> \n  as_tibble() |> \n  group_by(State) |> \n  summarise(Takings = sum(Takings), Occupancy = sum(Occupancy)) |> \n  arrange(desc(Takings))\n\n# A tibble: 8 × 3\n  State                        Takings Occupancy\n  <chr>                          <dbl>     <dbl>\n1 New South Wales                2595.      259.\n2 Queensland                     2061.      250.\n3 Victoria                       1517.      258.\n4 Western Australia               849.      259.\n5 South Australia                 381.      252.\n6 Northern Territory              265.      262.\n7 Australian Capital Territory    227.      304.\n8 Tasmania                        193.      238.\n\n\n\n\n\n\n\n\nYour turn!\n\n\n\nUsing the tourism dataset, which Purpose of travel is most common in each state?\nSome starter code has been provided for you in the day 1 exercises.\nHint: since you no longer want to consider changes over time, you’ll need to convert the data back to a tibble."
  },
  {
    "objectID": "sessions/day1/exercises.html#visualising-time-series",
    "href": "sessions/day1/exercises.html#visualising-time-series",
    "title": "Exercises",
    "section": "Visualising time series",
    "text": "Visualising time series\nThere are a few common visualisation techniques specific to time series, however cross-sectional graphics also work well for time series data. The main difference is that we like to maintain the ordered and connected nature of time.\n\nTime plots\nThe simplest graphic for time series is the time series plot, which shows the variable of interest (on the y-axis) against time (on the x-axis). This plot can be created manually with ggplot2, or automatically plotted from the tsibble with autoplot().\n\nlibrary(fable)\nlibrary(ggplot2)\nguinea_rice |> \n  autoplot(Production)\n\n\n\n\nIn this plot we can see that Production increases over time (known as trend). The increase is mostly smooth but there are a couple anomalies in 2001 and 2008.\n\n\n\n\n\n\nPlotting the time variable\n\n\n\nIn this plot, Production and Year are two continuous variables. We would often like to plot two continuous variables with a scatter plot, however in time-series we prefer to connect the observations from one year to the next to give this line chart.\n\n\nWe can also use autoplot() to produce a time plot of many series, but be careful not to plot too many lines at once!\n\naus_accommodation |> \n  autoplot(Takings)\n\n\n\n\nIn this plot of Australian accommodation takings, we see that most states have increasing takings over time (upward trend). We can also notice a repeating up and down pattern, which upon closer inspection repeats every year. This repeating annual pattern is known as seasonality, and we can see that some states are more seasonal than others.\nLet’s focus on the sunny holiday destination of Queensland, and use different plots to better understand the seasonality.\n\naus_accommodation |> \n  filter(State == \"Queensland\") |> \n  autoplot(Takings)\n\n\n\n\n\n\n\n\n\n\nYour turn!\n\n\n\nUsing the tourism dataset, create time plots of the data. Which patterns can you observe?\nSome starter code has been provided for you in the day 1 exercises.\nHint: there are too many series to show in a single plot, so filter and summarise series of interest to you.\n\n\n\n\nSeasonal plots\nIt can be tricky to see which quarter has maximum accommodation takings from a time plot. Instead, it is better to use a seasonal plot with gg_season() from feasts.\n\nlibrary(feasts)\naus_accommodation |> \n  filter(State == \"Queensland\") |> \n  gg_season(Takings)\n\n\n\n\nHere we can see that the Q3 and Q4 takings are higher than Q1 and Q2, this is known as the seasonal peak and trough respectively.\n\n\n\n\n\n\nThe season plot\n\n\n\nThe seasonal plot is very similar to the time plot, but the x-axis now wraps over years. This allows us to more easily compare the years and find common patterns, like which month or quarter is biggest and smallest.\n\n\n\n\n\n\n\n\nYour turn!\n\n\n\nUsing the tourism dataset, create a seasonal plot for the total holiday travel to Australia over time. In which quarter is holiday travel highest and lowest?\nSome starter code has been provided for you in the day 1 exercises.\n\n\n\n\nSeasonal subseries plot\nAnother useful plot to understand the seasonal pattern of a time series is the subseries plot, it can be created with gg_subseries(). This plot is splits each month / quarter into separate facets (mini-plots), which shows how the values within each season change over time. The blue lines represent the average, which is a useful way to see the overall seasonality at a glance.\n\naus_accommodation |> \n  filter(State == \"Queensland\") |> \n  gg_subseries(Takings)\n\n\n\n\n\n\n\n\n\n\nSeasonal sub-series plots\n\n\n\nThe upward lines in each facet of this plot shows the trend of the data, however if the lines went in different directions that would imply the shape of the seasonality is changing over time.\nSeasonal plots work best after removing trend, which we will see how to do tomorrow!\n\n\nLet’s see this plot with a different dataset, recent beer production in Australia.\n\naus_beer <- tsibbledata::aus_production |> \n  filter(Quarter >= yearquarter(\"1992 Q1\")) |> \n  select(Beer)\naus_beer |> \n  autoplot(Beer)\n\n\n\n\nAt a glance, this looks like the it is very seasonal and has a slight downward trend. However the seasonal subseries plot reveals that the trend is misleading!\n\naus_beer |> \n  gg_subseries(Beer)\n\n\n\n\nHere we see that only Q4 (the peak) has a downward trend, while the other quarters are staying roughly the same. The seasonality is changing shape over time.\n\n\n\n\n\n\nChanging seasonality\n\n\n\nLook back at the time plot and focus only on the Q4 peaks, can you see these values decreasing over time? Now look at the Q1-Q3 throughs, how do they change over time?\nThis can be tricky to notice in the time plot, which is why seasonal subseries plots can be particularly helpful!\n\n\n\n\n\n\n\n\nYour turn!\n\n\n\nUsing the tourism dataset, create a seasonal subseries plot for the total business travel to Victoria over time. Does the seasonal pattern change over time?\nSome starter code has been provided for you in the day 1 exercises.\n\n\n\n\nACF plots\nThese plots may look a bit strange at first, but they are very useful for seeing all of the time series dynamics in a single plot. ACF is the ‘auto-correlation function’, essentially a measure of how similar a time series is to the lags of itself. Looking at these correlations can reveal trends, seasonality, cycles, and more subtle patterns. You can create an ACF plot using a combination of ACF() and autoplot().\n\nguinea_rice |> \n  ACF(Production) |> \n  autoplot()\n\n\n\n\nThe rice production of Guinea has an upward trend, which produces a gradual decay in the ACF.\n\naus_beer |> \n  ACF(Beer) |> \n  autoplot()\n\n\n\n\nThe recent beer production of Australia has lots of seasonality and no trend, which creates large peaks at the seasonal lags in the ACF. Every 4 quarters we see a large ACF spike.\n\naus_accommodation |> \n  summarise(Occupancy = sum(Occupancy)) |> \n  ACF(Occupancy) |> \n  autoplot()\n\n\n\n\nThe total occupancy of Australia’s short-term accommodation is both trended and seasonal, which results in a slowly decaying ACF with peaks every seasonal lag (4, 8, 12, …).\nConsider the number of Snowshoe Hares which were traded by the Hudson Bay Company.\n\ntsibbledata::pelt |> \n  autoplot(Hare)\n\n\n\n\nTo the untrained eye, this series has lots of up and down patterns - a bit like seasonality. However this pattern is cyclical, not seasonal. The ACF plot can help us distinguish cycles from seasonality.\n\n\n\n\n\n\nSeasonal or cyclic?\n\n\n\nSeasonality is a consistent repeating pattern, where the shape shape with similar peak and trough repeats at the same time interval.\nCyclical patterns are less consistent, with varying peaks and troughs that repeats over a varied time period.\n\n\nLet’s see the ACF for this dataset\n\ntsibbledata::pelt |> \n  ACF(Hare) |> \n  autoplot()\n\n\n\n\nNotice that the peak at lag 10 is less symmetric and ‘sharp’, this is because the pattern usually repeats every 10 years but sometimes 9 or 11. This is unlike seasonality, which has a sharper peak in the ACF due to the consistent time period between patterns.\n\n\n\n\n\n\nYour turn!\n\n\n\nIdentify which ACF matches the time plots in the following figures by identifying the patterns of trend, seasonality, and cycles in the ACF plots.\n\n\n\n\n\n\n\n\n\nYour turn!\n\n\n\nUsing the tourism dataset, create an ACF plot for the total travel to Australia over time. Can you identify patterns of trend and seasonality from this plot?\nSome starter code has been provided for you in the day 1 exercises.\n\n\n\n\n\n\n\n\nACF model evaluation\n\n\n\nImportantly, ACF plots can also tell us when there are no patterns/autocorrelations in the data (white noise).\nWe’ll be revisiting this plot to evaluate our models on day 5. We hope that a model uses all available information, and ACF plots can show if there is any patterns left over."
  },
  {
    "objectID": "sessions/day2/exercises.html",
    "href": "sessions/day2/exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Learn\nMitch’s section to learn the concepts on various datasets\n\n\nApply\nBahman’s section to apply the concepts to health data"
  },
  {
    "objectID": "sessions/day3/exercises.html",
    "href": "sessions/day3/exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Learn\nMitch’s section to learn the concepts on various datasets\n\n\nApply\nBahman’s section to apply the concepts to health data"
  },
  {
    "objectID": "sessions/day4/exercises.html",
    "href": "sessions/day4/exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Learn\nMitch’s section to learn the concepts on various datasets\n\n\nApply\nBahman’s section to apply the concepts to health data"
  },
  {
    "objectID": "sessions/day5/exercises.html",
    "href": "sessions/day5/exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Learn\nMitch’s section to learn the concepts on various datasets\n\n\nApply\nBahman’s section to apply the concepts to health data"
  },
  {
    "objectID": "sessions/template.html",
    "href": "sessions/template.html",
    "title": "{{title}}",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "sessions/template.html#lab-sessions",
    "href": "sessions/template.html#lab-sessions",
    "title": "{{title}}",
    "section": "Lab sessions",
    "text": "Lab sessions"
  }
]